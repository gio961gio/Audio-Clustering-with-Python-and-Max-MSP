{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lZsKJpaRs_77",
        "vjeIg6jhnPg_"
      ],
      "mount_file_id": "1P7Zm-j6X0bzp7GuA6hHMawLLvF1SJ3wa",
      "authorship_tag": "ABX9TyPV/+gqsfEgLPLjxgp+9Xc+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gio961gio/Audio-Clustering-with-Python-and-Max-MSP/blob/main/Audio_Clustering_with_Python_and_Max_MSP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Cloning Github**\n",
        "import sys\n",
        "!git clone https://github.com/gio961gio/Audio-Clustering-with-Python-and-Max-MSP.git\n",
        "sys.path.append(\"/content/Audio-Clustering-with-Python-and-Max-MSP\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IX-PzpmpkLBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Setup Load Dataset (Google Drive Link)**\n",
        "!pip install rarfile\n",
        "!pip install pydub\n",
        "\n",
        "\n",
        "import os\n",
        "import gdown\n",
        "import rarfile\n",
        "\n",
        "# Definisci il link condiviso al file RAR su Google Drive\n",
        "rar_file_link = \"https://drive.google.com/file/d/1QBaEbp3psMadVr3cgdACvT_43bka7tvO/view?usp=drive_link\" # @param {type:\"string\"}\n",
        "\n",
        "# Estrai l'ID del file RAR dal link condiviso\n",
        "file_id = rar_file_link.split('/')[-2]\n",
        "\n",
        "# Scarica il file RAR da Google Drive\n",
        "rar_file_path = \"/content/750_audio.rar\" # @param {type:\"string\"}\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', rar_file_path, quiet=False)\n",
        "\n",
        "\n",
        "# Specifica la directory di destinazione dell'estrazione\n",
        "extraction_path = \"/content/extracted_files/\"  # @param {type:\"string\"}\n",
        "\n",
        "# Crea la directory di destinazione se non esiste\n",
        "os.makedirs(extraction_path, exist_ok=True)\n",
        "\n",
        "# Esegui l'estrazione dei file RAR\n",
        "with rarfile.RarFile(rar_file_path, 'r') as rar:\n",
        "    rar.extractall(extraction_path)"
      ],
      "metadata": {
        "id": "xAUP2893FUrY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Audio Features Extractor**\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "import warnings\n",
        "from audio_stuff import extract_audio_features_from_directory\n",
        "\n",
        "\n",
        "# Ignora i warning\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def conta_file_in_cartella(cartella):\n",
        "    # Ottieni la lista dei file nella cartella\n",
        "    lista_file = os.listdir(cartella)\n",
        "\n",
        "    # Conta quanti elementi nella lista sono file (escludendo le directory)\n",
        "    num_file = sum(os.path.isfile(os.path.join(cartella, f)) for f in lista_file)\n",
        "\n",
        "    return num_file\n",
        "\n",
        "\n",
        "# Ottieni il numero di file nella cartella specificata\n",
        "num_file = conta_file_in_cartella(extraction_path)\n",
        "\n",
        "\n",
        "\n",
        "num_samples = 10 # @param {type:\"integer\"}\n",
        "\n",
        "if num_samples < 1 or num_samples > num_file:\n",
        "    raise ValueError(f\"Number of samples must be between 1 and {num_file}.\")\n",
        "\n",
        "\n",
        "\n",
        "# Ottieni la lista dei file audio estratti\n",
        "audio_files = [os.path.join(extraction_path, filename) for filename in os.listdir(extraction_path) if filename.endswith('.wav')][:]\n",
        "audio_files = sorted(audio_files, key=lambda x: int(x.split('/')[-1].split('_')[0]))\n",
        "audio_files_ = audio_files[:num_samples]\n",
        "\n",
        "\n",
        "\n",
        "combined_features = extract_audio_features_from_directory('/content/extracted_files', num_mfcc=13, num_samples=num_samples)\n",
        "\n",
        "\n",
        "# Trasforma la lista di caratteristiche in un array numpy\n",
        "features_array = np.array(combined_features)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features_array)\n",
        "\n",
        "\n",
        "# Salva scaled_features in un file\n",
        "np.save('scaled_features.npy', scaled_features)\n"
      ],
      "metadata": {
        "id": "YJVubWqrDGrf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Clustering 2D**\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#Parametri\n",
        "n_clusters = 4 # @param {type:\"integer\"}\n",
        "init='k-means++'  # @param [\"k-means++\", \"random\"]\n",
        "n_init=100 # @param {type:\"integer\"}\n",
        "max_iter=10 # @param {type:\"integer\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Carica i dati da file\n",
        "scaled_features = np.load('scaled_features.npy')\n",
        "\n",
        "\n",
        "# Crea il modello PCA con 2 componenti principali\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Applica la PCA alle feature scalate (scaled_features)\n",
        "reduced_features = pca.fit_transform(scaled_features)\n",
        "\n",
        "# # Riscala i risultati dell'PCA tra 0 e 1\n",
        "scaler = MinMaxScaler()\n",
        "reduced_features = scaler.fit_transform(reduced_features)\n",
        "\n",
        "# Esegui il clustering sulle feature ridotte\n",
        "minibatch_kmeans = MiniBatchKMeans(n_clusters=n_clusters, init=init, n_init=n_init, max_iter=max_iter)\n",
        "cluster_labels = minibatch_kmeans.fit_predict(reduced_features)\n",
        "\n",
        "# Calcola il Silhouette Score per valutare la bontà del clustering\n",
        "silhouette_avg = silhouette_score(reduced_features, cluster_labels)\n",
        "print(f\"Silhouette Score: {silhouette_avg}\")\n",
        "\n",
        "# # Calcola l'inerzia (inertia) per valutare la compattazione dei cluster\n",
        "# inertia = minibatch_kmeans.inertia_\n",
        "# print(f\"Inertia (Inerzia): {inertia}\")\n",
        "\n",
        "\n",
        "# Visualizza i risultati del clustering\n",
        "plt.figure(figsize=(10, 6))\n",
        "unique_labels = np.unique(cluster_labels)\n",
        "for label in unique_labels:\n",
        "    cluster_points = reduced_features[cluster_labels == label]\n",
        "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'Cluster {label + 1}')\n",
        "\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "\n",
        "plt.title('Risultato del Clustering dei Loop Audio con MiniBatchKMeans e PCA')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Bh8FKGIcPARF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save/Load Model (Optional)"
      ],
      "metadata": {
        "id": "lZsKJpaRs_77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save Model\n",
        "import joblib  # Per il salvataggio e il caricamento del modello\n",
        "model_name = 'modelD.pkl' # @param {type:\"string\"}\n",
        "joblib.dump(minibatch_kmeans, model_name)"
      ],
      "metadata": {
        "id": "5biplSausI2b",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load Model\n",
        "import joblib\n",
        "\n",
        "model_name = 'modelD.pkl' # @param {type:\"string\"}\n",
        "\n",
        "minibatch_kmeans = joblib.load(model_name)\n",
        "cluster_labels = minibatch_kmeans.fit_predict(reduced_features)\n",
        "\n",
        "# # Calcola il Silhouette Score per valutare la bontà del clustering\n",
        "# silhouette_avg = silhouette_score(reduced_features, cluster_labels)\n",
        "# print(f\"Silhouette Score: {silhouette_avg}\")\n",
        "\n",
        "# # Calcola l'inerzia (inertia) per valutare la compattazione dei cluster\n",
        "# inertia = minibatch_kmeans.inertia_\n",
        "# print(f\"Inertia (Inerzia): {inertia}\")\n",
        "\n",
        "\n",
        "# Visualizza i risultati del clustering\n",
        "plt.figure(figsize=(10, 6))\n",
        "unique_labels = np.unique(cluster_labels)\n",
        "for label in unique_labels:\n",
        "    cluster_points = reduced_features[cluster_labels == label]\n",
        "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'Cluster {label + 1}')\n",
        "\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "\n",
        "plt.title('Risultato del Clustering dei Loop Audio con MiniBatchKMeans e PCA')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BXzrBzamsrTS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Files for Max MSP"
      ],
      "metadata": {
        "id": "vjeIg6jhnPg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title IMUBU\n",
        "\n",
        "import string\n",
        "\n",
        "letters = string.ascii_uppercase\n",
        "cluster_to_letter = {}\n",
        "\n",
        "# Mappa i cluster a lettere maiuscole\n",
        "for x in range(n_clusters):\n",
        "    cluster_to_letter[x] = letters[x]\n",
        "\n",
        "# Crea una lista di coordinate, numero di cluster e lettere maiuscole corrispondenti\n",
        "results = []\n",
        "\n",
        "for label in unique_labels:\n",
        "    cluster_points = reduced_features[cluster_labels == label]\n",
        "    cluster_letter = cluster_to_letter[label]\n",
        "    cluster_num = label + 1\n",
        "\n",
        "    for point in cluster_points:\n",
        "        x, y = point[:2]  # Prendi solo le prime due coordinate PC1 e PC2\n",
        "        x = round(x, 4)  # Approssima a quattro cifre decimali\n",
        "        y = round(y, 4)  # Approssima a quattro cifre decimali\n",
        "        results.extend([x, y, 0, cluster_num, cluster_num, cluster_letter])\n",
        "\n",
        "# Nome del file in cui salvare i risultati\n",
        "file_name = \"risultatiD.txt\"\n",
        "\n",
        "# Scrivi i risultati nel file, separati da spazi\n",
        "with open(file_name, 'w') as file:\n",
        "    result_str = \" \".join(map(str, results))\n",
        "    file.write(f\"{result_str}\\n\")\n",
        "\n",
        "print(f\"Results saved in {file_name}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "w0WZnNe1mpmj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title CHOOSER\n",
        "\n",
        "# Nome del file in cui salvare i risultati\n",
        "file_name = \"coordinate_risultatiD.txt\"\n",
        "\n",
        "# Scrivi le coordinate approssimate a due cifre decimali nel file\n",
        "with open(file_name, 'w') as file:\n",
        "    for label in unique_labels:\n",
        "        cluster_points = reduced_features[cluster_labels == label]\n",
        "        for point in cluster_points:\n",
        "            x, y = point[:2]  # Prendi solo le prime due coordinate PC1 e PC2\n",
        "            x = round(x, 2)  # Approssima a due cifre decimali\n",
        "            y = round(y, 2)  # Approssima a due cifre decimali\n",
        "            file.write(f\"append {x:.2f}:{y:.2f}, \")\n",
        "\n",
        "print(f\"Coordinates of results saved in {file_name}\")\n"
      ],
      "metadata": {
        "id": "7Lk1-_U24ckM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering 3D (Optional)"
      ],
      "metadata": {
        "id": "0CMYlWFo_vMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Clustering 3D**\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#Parametri\n",
        "n_clusters = 4 # @param {type:\"integer\"}\n",
        "init='k-means++'  # @param [\"k-means++\", \"random\"]\n",
        "n_init=100 # @param {type:\"integer\"}\n",
        "max_iter=10 # @param {type:\"integer\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "scaled_features = np.load('scaled_features.npy')\n",
        "\n",
        "# Crea il modello PCA con 3 componenti principali\n",
        "pca = PCA(n_components=3)\n",
        "\n",
        "# Applica la PCA alle feature scalate\n",
        "reduced_features = pca.fit_transform(scaled_features)\n",
        "\n",
        "# # Riscala i risultati dell'PCA tra 0 e 1\n",
        "scaler = MinMaxScaler()\n",
        "reduced_features = scaler.fit_transform(reduced_features)\n",
        "\n",
        "\n",
        "# Esegui il clustering sulle feature ridotte\n",
        "minibatch_kmeans = MiniBatchKMeans(n_clusters=n_clusters, init=init, n_init=n_init, max_iter=max_iter)\n",
        "cluster_labels = minibatch_kmeans.fit_predict(reduced_features)\n",
        "\n",
        "# # Calcola il Silhouette Score per valutare la bontà del clustering\n",
        "# silhouette_avg = silhouette_score(reduced_features, cluster_labels)\n",
        "# print(f\"Silhouette Score: {silhouette_avg}\")\n",
        "\n",
        "# # Calcola l'inerzia (inertia) per valutare la compattazione dei cluster\n",
        "# inertia = minibatch_kmeans.inertia_\n",
        "# print(f\"Inertia (Inerzia): {inertia}\")\n",
        "\n",
        "# Visualizza i risultati del clustering in un grafico 3D\n",
        "fig = go.Figure()\n",
        "unique_labels = np.unique(cluster_labels)\n",
        "for label in unique_labels:\n",
        "    cluster_points = reduced_features[cluster_labels == label]\n",
        "    fig.add_trace(go.Scatter3d(x=cluster_points[:, 0], y=cluster_points[:, 1], z=cluster_points[:, 2], mode='markers', name=f'Cluster {label + 1}'))\n",
        "\n",
        "fig.update_layout(scene=dict(xaxis_title='PC1', yaxis_title='PC2', zaxis_title='PC3'), title='Risultato del Clustering dei Loop Audio con MiniBatchKMeans e PCA (3D)')\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "cYSt4gM6tqfB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}